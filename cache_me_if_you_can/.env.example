# Application Configuration
# Use mock data for demos (true/false)
USE_MOCK_DATA=false

# Database Configuration
# Supported: mysql, mariadb, postgresql
DB_ENGINE=mysql
DB_HOST=localhost
DB_PORT=3306
DB_USER=root
DB_PASSWORD=secretpassword
DB_NAME=flughafendb_large

# Cache Configuration
# Supported: redis, valkey, memcached
CACHE_ENGINE=valkey
CACHE_HOST=localhost
CACHE_PORT=6379

# Cache TTL (Time To Live) in seconds
# Default: 3600 (1 hour)
CACHE_TTL=3600

# Ollama Configuration
# Model to use for NLP to SQL conversion
# Options: tinyllama, codellama, llama2, mistral, etc.
OLLAMA_MODEL=codellama
OLLAMA_URL=http://localhost:11434/api/generate

# Embedding Model Configuration
# Model for semantic search embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Semantic Search Configuration
# Similarity threshold for semantic search (0.0 to 1.0)
SIMILARITY_THRESHOLD=0.70

# Knowledge Base Path
KNOWLEDGE_BASE_PATH=../knowledge_base

# Vector Database Configuration
# Separate vector database for semantic search (can be same as cache or differentt
# Supported: valkey
VECTOR_ENGINE=valkey
VECTOR_HOST=localhost
VECTOR_PORT=16379
