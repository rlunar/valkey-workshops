# NLP to SQL - Example Output

## With Better Model (e.g., llama3.2, mistral)

```
============================================================
Natural Language to SQL Query Generator
============================================================
Loaded knowledge base from: /path/to/knowledge_base
Using model: llama3.2


============================================================
DEMO MODE - Running test queries
============================================================


1. Natural Language: Get airport with geographic details by IATA code JFK
------------------------------------------------------------
Generated SQL:
SELECT a.airport_id, a.iata, a.icao, a.name, ag.city, ag.country, ag.latitude, ag.longitude 
FROM airport a 
LEFT JOIN airport_geo ag ON a.airport_id = ag.airport_id 
WHERE a.iata = 'JFK';

ğŸ“Š Stats: â±ï¸  2.34s | ğŸ”¢ 1245 tokens | âš¡ 532.1 tokens/s


2. Natural Language: Show me all flights from JFK to LAX
------------------------------------------------------------
Generated SQL:
SELECT f.flight_id, f.flightno, f.departure, f.arrival, 
       a_from.name as departure_airport, a_to.name as arrival_airport 
FROM flight f 
INNER JOIN airport a_from ON f.`from` = a_from.airport_id 
INNER JOIN airport a_to ON f.`to` = a_to.airport_id 
WHERE a_from.iata = 'JFK' AND a_to.iata = 'LAX' 
LIMIT 20;

ğŸ“Š Stats: â±ï¸  3.12s | ğŸ”¢ 1567 tokens | âš¡ 502.2 tokens/s


3. Natural Language: Find 10 passengers from United States
------------------------------------------------------------
Generated SQL:
SELECT p.passenger_id, p.firstname, p.lastname, pd.city, pd.country 
FROM passenger p 
INNER JOIN passengerdetails pd ON p.passenger_id = pd.passenger_id 
WHERE pd.country = 'United States' 
LIMIT 10;

ğŸ“Š Stats: â±ï¸  2.89s | ğŸ”¢ 1423 tokens | âš¡ 492.4 tokens/s


4. Natural Language: How many bookings does passenger 1000 have?
------------------------------------------------------------
Generated SQL:
SELECT COUNT(b.booking_id) as total_bookings 
FROM booking b 
WHERE b.passenger_id = 1000;

ğŸ“Š Stats: â±ï¸  1.87s | ğŸ”¢ 1156 tokens | âš¡ 618.2 tokens/s


5. Natural Language: Flight manifest - all passengers on a specific flight 115
------------------------------------------------------------
Generated SQL:
SELECT b.seat, p.firstname, p.lastname, p.passportno, pd.country, b.price 
FROM booking b 
INNER JOIN passenger p ON b.passenger_id = p.passenger_id 
LEFT JOIN passengerdetails pd ON p.passenger_id = pd.passenger_id 
WHERE b.flight_id = 115 
ORDER BY b.seat ASC;

ğŸ“Š Stats: â±ï¸  3.45s | ğŸ”¢ 1678 tokens | âš¡ 486.4 tokens/s


============================================================
ğŸ“ˆ SUMMARY: 5 queries in 13.67s | 7069 total tokens
============================================================
```

## Interactive Mode Example

```
============================================================
INTERACTIVE MODE
============================================================
Enter your natural language queries (or 'quit' to exit)
============================================================


Your query: Show top 5 airlines by revenue

Generating SQL...

Generated SQL:
SELECT al.airline_id, al.airlinename, al.iata, 
       COUNT(DISTINCT f.flight_id) as total_flights, 
       SUM(b.price) as total_revenue 
FROM airline al 
INNER JOIN flight f ON al.airline_id = f.airline_id 
LEFT JOIN booking b ON f.flight_id = b.flight_id 
GROUP BY al.airline_id, al.airlinename, al.iata 
ORDER BY total_revenue DESC 
LIMIT 5;

ğŸ“Š Stats:
   â±ï¸  Time: 2.98s
   ğŸ”¢ Tokens: 1534 (prompt: 1245, response: 289)
   âš¡ Speed: 97.0 tokens/s


Your query: quit
Goodbye!
```

## Stats Explanation

- **â±ï¸ Time**: Total time taken to generate the SQL (includes network latency)
- **ğŸ”¢ Tokens**: Total tokens processed
  - **prompt**: Tokens in the input (context + query)
  - **response**: Tokens generated by the model
- **âš¡ Speed**: Generation speed in tokens per second (response tokens / time)

## Performance Notes

- **TinyLlama (1.1B)**: Fast but inaccurate, often hallucinates table names
- **Llama 3.2 (3B)**: Good balance, ~2-4s per query, decent accuracy
- **Mistral (7B)**: Better accuracy, ~3-5s per query
- **CodeLlama (7B+)**: Best for SQL, ~3-5s per query, highest accuracy

Token counts include the entire knowledge base context (~1000-1500 tokens) plus the query and response.
